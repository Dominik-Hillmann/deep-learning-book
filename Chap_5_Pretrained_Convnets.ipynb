{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pretrained Convnets</h1><br><br>\n",
    "Es ist möglich die Convolutional Base, also die ersten Conv und Max-Pooling-Schichten, bereits tranierter Netze zu nutzen. Auch wenn diese auf anderen Problemen traniert worden sind, dienen diese Schichten als Modell der visuellen Welt und können sich so als nützlich erweisen. Man kann vortrainerte Netze auf zwei Weisen verwenden: Feature Extraction und Fine-Tuning.<br><br>\n",
    "<b>1. Feature Extraction</b><br>\n",
    "Hier wird die alte Conv-Basis genutzt. Das bedeutet, dass die Convolution- und Max-Pooling Schichten anderer Netzwerke verwendet werden. Auf diesen wird ein neuer Klassifizierer aus Dense-Schichten gesetzt, der deinem Problem angepasst ist. Je \"weiter unten\" die Schichten sind, die man verwendet, desto generischer sind die gelernten Muster (unten z.B. \"schräger Strich\", oben \"Konzept Ohr\") und desto eher sind diese auf dein Problem anwendbar. Auch ist es gut, die Convbasis ähnlicher Probleme zu verwenden zu verwenden. So wird eine Basis, die urspünglich auf die Klassifizierung von vielen Tieren trainiert wurde auch für die binäre Klassifizierung von \"Hund/kein Hund\" nützlich sein, da in der Basis bereits das Konzept des Hundes zu finden ist.<br><br>\n",
    "Keras bringt bereits einige Convbasen mit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"input_1:0\", shape=(?, 150, 150, 3), dtype=float32) \n",
      "\n",
      "Tensor(\"input_1:0\", shape=(?, 150, 150, 3), dtype=float32) \n",
      "\n",
      "Tensor(\"block1_conv1/Relu:0\", shape=(?, 150, 150, 64), dtype=float32) \n",
      "\n",
      "Tensor(\"block1_conv2/Relu:0\", shape=(?, 150, 150, 64), dtype=float32) \n",
      "\n",
      "Tensor(\"block1_pool/MaxPool:0\", shape=(?, 75, 75, 64), dtype=float32) \n",
      "\n",
      "Tensor(\"block2_conv1/Relu:0\", shape=(?, 75, 75, 128), dtype=float32) \n",
      "\n",
      "Tensor(\"block2_conv2/Relu:0\", shape=(?, 75, 75, 128), dtype=float32) \n",
      "\n",
      "Tensor(\"block2_pool/MaxPool:0\", shape=(?, 37, 37, 128), dtype=float32) \n",
      "\n",
      "Tensor(\"block3_conv1/Relu:0\", shape=(?, 37, 37, 256), dtype=float32) \n",
      "\n",
      "Tensor(\"block3_conv2/Relu:0\", shape=(?, 37, 37, 256), dtype=float32) \n",
      "\n",
      "Tensor(\"block3_conv3/Relu:0\", shape=(?, 37, 37, 256), dtype=float32) \n",
      "\n",
      "Tensor(\"block3_pool/MaxPool:0\", shape=(?, 18, 18, 256), dtype=float32) \n",
      "\n",
      "Tensor(\"block4_conv1/Relu:0\", shape=(?, 18, 18, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block4_conv2/Relu:0\", shape=(?, 18, 18, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block4_conv3/Relu:0\", shape=(?, 18, 18, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block4_pool/MaxPool:0\", shape=(?, 9, 9, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block5_conv1/Relu:0\", shape=(?, 9, 9, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block5_conv2/Relu:0\", shape=(?, 9, 9, 512), dtype=float32) \n",
      "\n",
      "Tensor(\"block5_conv3/Relu:0\", shape=(?, 9, 9, 512), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# diese sind in keras.applications zu finden\n",
    "# das ImageNet-Problem enthielt mehrere Katzen- und Hundeklassen\n",
    "# wir nehmen die Basis des VGG16-Netzwerks\n",
    "\n",
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False, # soll der Klassifizierer mit einbezogen werden?\n",
    "    input_shape = (150, 150, 3) # Wie große sind die Bilder? (height, width, channels (rgb))\n",
    ")\n",
    "conv_base.summary()\n",
    "\n",
    "layers = [layer.input for layer in conv_base.layers]\n",
    "for layer in layers:\n",
    "    print(layer, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt, wo die Basis importiert worden ist, kann man auf zwei verschiednen Arten weitermachen:<br>\n",
    "1. Du kannst einmal alle Bilder durch die Basis laufen lassen und die Numpy-Arrays in der Form (4, 4, 512) aufzeichen und diese später zum Trainieren des Klassifizierers nutzen. Vorteile: schnell, Nachteile: keine Data-Augmentation möglich, also wird schneller Overfitting eintreten.\n",
    "2. Zum anderen kannst du deinen Klassifizierer gleich auf die Basis setzen, die Basis einfrieren und dann diese beiden Teile zusammen trainieren. Vorteile: Data Augmentation möglich, Nachteil: sehr langsam, da rechn. teuer.\n",
    "\n",
    "\n",
    "In dem hier vorliegenden Problem sollte eigentlich die zweite Variante genutzt werden, da bei CNNs mit kleinem Datensatz Data Augmentation essentiell ist.<br><br>\n",
    "<b>1.1. Seperate Nutzung der beiden Teile</b><br>\n",
    "Als erstes wirst du wieder dem ImageGenerator die Bilder als NumPy-Arrays entziehen und dann das Ergebnis der Basis mittels der <code>predict()</code>-Methode aufzeichnen und später als Datensetz zum Trainieren des Klassifizieres verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \"/home/dominik/Documents/Datasets/cats_and_doggos/small\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale = 1.0 / 255.0)\n",
    "batch_size = 20\n",
    "\n",
    "# Gets you the (features, labels), feautures are predicted by the base from the pics.\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape = (sample_count, 4, 4, 512)) # shape of output of base\n",
    "    labels = np.zeros(shape = sample_count) # label vector as long as sample\n",
    "    \n",
    "    # will return images from directory as generator\n",
    "generator = data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "    \n",
    "for inputs_batch, labels_batch in generator:\n",
    "    print(labels_batch) # HIER PROBLEM, KANN LABEL NICHT FINDEN\n",
    "i = 0\n",
    "    #for inputs_batch, labels_batch in generator:\n",
    "    #    features_batch = conv_base.predict(inputs_batch, steps = batch_size) # takes the predictions of the base\n",
    "    #    features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    #    labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    #    i += 1\n",
    "    #    if i * batch_size >= sample_count:\n",
    "    #        break\n",
    "    #return features, labels\n",
    "\n",
    "#train_features, train_labels = extract_features(train_dir, 2000)\n",
    "#validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "#test_features, test_labels = extract_features(test_dir, 1000)\n",
    "    \n",
    "# ... S. 22/47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.2 Feature Extraction mit Data Augmentation</b><br>\n",
    "Hier werden die dicht vernetzten Schichten auf die Convolution-Basis aufgesetzt, was wesentlich teurer und langsamer ist. Dazu müssen die Convolution-Schichten eingefroren werden, da sonst die vorher gelernten Muster verändert werden. Da die Gewichte der <code>Dense</code>-Schichten  zufällig initialisiert sind, werden große Updates durch das Netzwerk propagieren und so die gelernten Muster zerstören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conv_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ab598916669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_base' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Einfrieren der conv_base\n",
    "conv_base.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Hier den Code von S. 25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
