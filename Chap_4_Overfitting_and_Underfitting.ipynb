{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Overfitting and Underfitting</h1><br><br>\n",
    "Wie bereits erklärt beschreibt Overfitting den Prozess, wenn das Modell beginnt, Muster eines Datensatzes zu lernen, die sich nicht auf ungesehene Daten übertragen lassen und deshalb irrelevant sind. Mit Overfitting umzugehen ist der Schlüssel im Erstellen guter Modelle. Beim Trainieren des Modells gibt es 2 Prozesse: Optimierung und Generalisierung. Optimierung ist das Bestreben des Algorithmus, das Modell möglichst gut den Traninigsdaten anzupassen. Generalisierung ist das Bestreben, eine gute Performance auf nie zuvor gesehenen Daten aufzuweisen. Am Anfang des Traninigs ist das Modell noch underfittet. Es können noch relevante, generalisierbare Muster gelernt werden und Optimierung und Generalisierbarkeit sind noch korrelliert. Dann kommt ein Zeitpunkt, an dem die Metriken der Validierungsdaten weniger bis gar keine Verbesserung mehr aufweisen. Hier beginnt das Overfitting. Nun werden nicht-generalisierbare Muster in den Trainingsdaten gelernt. Welche Lösungen gibt es gegen Overfitting?<br><br>\n",
    "<b>Mehr Traningsdaten</b>\n",
    "Ein Modell, das auf mehr Daten trainiert ist, kann besser generalisieren.<br><br>\n",
    "<b>Netzwerkgröße einschränken</b><br>\n",
    "Je mehr Knotenpunkte existieren, desto mehr Muster kann das Netzwerk internalisieren. Es besteht also die Möglichkeit, das Netzwerk so weit einzuschränken, dass nur noch relevante, generalisierbare (und auch die wichtigsten, aus Sicht des NN) zu lernen.<br><br>\n",
    "<b>Gewichtsregularisierung</b><br>\n",
    "Ähnlich Occams Rasiermesser: Wenn zwei Theorien das gleiche erklären, an ist mit größerer Wahrscheinlichkeit die einfachere richtig, weil diese weniger Annahmen macht. \n",
    "Ebenso ist es bei einem einfacherern NN weniger wahrscheinlich, dass es overfittet. Das einfachere NN ist jenes, welches weniger Entropie aufweist, also entweder weniger Knotenpunkte, wie zuvor, oder Gewichte, deren Werte weniger weit auseinander liegen. Das kann man bezwecken, indem man zur Loss Function ein Strafterm addiert, der das Netzwerk für große Gewichte bestraft. Dabei ist L1-Regularisierung der absolute Wert aller Gewichte und L2-Regularisierung der quadrierte Wert aller Gewichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# so werden sie in Keras eingefügt\n",
    "from keras import regularizers\n",
    "# ...\n",
    "model.add(layers.Dense(\n",
    "    16,\n",
    "    kernel_regularizer = regularizers.l2(0.001),\n",
    "    activation = 'relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei bedeutet <code>l2(0.001)</code>, dass 0.001 * jeweiliges Gewicht für jedes Gewicht zur Loss Functions addiert wird.<br><br>\n",
    "<b>Dropout einfügen</b><br>\n",
    "Hier werden random Gewichte auf 0 gesetzt. Das Ziel dahinter ist, dass irrelevante Strukturen weniger tief im Modell inprägniert sind und sie nur funktionieren, wenn immer alle Gewichte vorhanden sind. Werden sie auf Null gesetzt, könnten diese unsignifikanten Muster aufgebrochen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sie werden so eingefügt\n",
    "model.add(layers.Dropout(0.5))\n",
    "# 0.5: 50% der Gewichte fallen aus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
