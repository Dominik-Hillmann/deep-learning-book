{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fortgeschrittene Deep-Learning-Techniken\n",
    "\n",
    "## Nichtlineare Modelle\n",
    "Oftmals ist es von Nutzen, über eine rein lineare Anordnung der Schichten hinauszugehen. Ein möglicher Fall ist ein multimodaler Inputs, bspw. willst du den Preis eines Produktes voraussage, indem eine Textbeschreibung, Verkaufszahlen und ein Bild des Produkts eingespeist werden, weshalb CNN-, RNN- und dicht vernetzte Schichten als Input-Schichten benötigt werden.\n",
    "<img src=\"./imgs/Multimodal_Input.png\">\n",
    "Eine weitere Möglichkeit ist multimodaler Output. So kann gleichzeitig das Genre und das Veröffentlichungsdatum eines Buches ermittelt werden. Da wahrscheinlich Korrelation zwischen beiden Eigenschaften existiert, ist es von Nutzen, eine gemeinsame Basis von Schichten zu nutzen.\n",
    "<img src=\"./imgs/Multimodal_Output.png\">\n",
    "Ein weiterer Trend ist das Einspeisen des Outputs einer früheren Schicht als Teilinput einer späteren Schicht, um Informationsverlust zu verhindern.\n",
    "<img src=\"./imgs/nonlinear_cnn.png\">\n",
    "\n",
    "## Vergleich der Sequentiellen API mit der Funktionalen API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Zunächst sequentiellen Modell\n",
    "seq_model = Sequential()\n",
    "seq_model.add(Dense(32, activation = 'relu', input_shape = (64, )))\n",
    "seq_model.add(Dense(32, activation = 'relu'))\n",
    "seq_model.add(Dense(10, activation = 'softmax'))\n",
    "print(seq_model.summary())\n",
    "\n",
    "# Funktionales Modell\n",
    "input_tensor = Input(shape = (64, )) # extra Defintion des Inputs\n",
    "x = Dense(32, activation = 'relu')(input_tensor) # Sichten geben wieder Funktion, deren Parameter vorangegangene Schicht ist\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "output_tensor = Dense(10, activation = 'relu')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor) # Modell wird letztendlich bereit gemacht durch diesen Befehl\n",
    "# Hier bringt Keras alle Schichten vom Input zum Output zusammen in eine azyklische Struktur\n",
    "# Keras prüft, ob der Input über einen Graphen zurückführend zum Input führt\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Input-Modelle\n",
    "Diese Modelle müssen ihre Inputs an einem Punkt vereinigen, was typischerweise mit\n",
    "* `keras.layers.add` oder\n",
    "* `keras.layers.concatenate`\n",
    "Als Beispiel gilt hier ein Frage-Antwort-System. Inputs sind der Referenztext und eine Frage und der Output ist die Antwort, `softmax` über ein vordefiniertes Vokabular. \n",
    "<img src=\"./imgs/question_answer.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           1284224     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           641088      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, Input\n",
    "\n",
    "text_vocab_size = 10000\n",
    "question_vocab_size = 10000\n",
    "answer_vocab_size = 500\n",
    "\n",
    "text_input = Input(shape = (None, ), dtype = 'int32', name = 'text')\n",
    "embedded_text = layers.Embedding(64, text_vocab_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape = (None, ), dtype = 'int32', name = 'question')\n",
    "embedded_question = layers.Embedding(32, question_vocab_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenate = layers.concatenate([encoded_text, encoded_question], axis = -1)\n",
    "\n",
    "answer = layers.Dense(answer_vocab_size, activation = 'softmax')(concatenate)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analog wird ein Multi-Output-Modell erstellt.\n",
    "\n",
    "### Flaschenhälse für Repäsentation\n",
    "Jede Schicht hat in einem sequentiellen Modell nur Zugriff auf die Information, die von der vorhergehenden Schicht weitergegeben wurde. Ist eine bestimmte Schicht kleiner als benötigt, so kann diese auch nur diese kleinere Menge an Informationen weitergeben. Die Schicht \"schneidet\" nützliche Information vorzeitig ab.\n",
    "\n",
    "### Vanishing Gradient\n",
    "Wird ein Netzwerk zu groß, kann das Feedbacksignal der Backpropagation nur geschwächt oder gar nicht in die ersten Schichten vordringen, was vanishing gradient problem genannt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Weight Sharing\n",
    "Eine wichtige Eigenschaft der funktionalen API ist die Möglichkeit, Schichten wiederzuverwenden. Das emöglicht es verschiedenen Modellen Zweige zu besitzen, die auf den gleichen Gewichten agieren und somit die gleichen Repäsentation.\n",
    "\n",
    "Ein Beispiel wäre ein Modell, das die semantische Ähnlichkeit zweier Sätze beurteilen soll. Es hat die Inputs der Sätze A und B. Semantische Ähnlichkeit ist eine symmetrische Beziehung: die Beziehung zwischen A und B ist die gleiche wie zwischen B und A. Wir wollen also keine zwei seperate Modelle erstellen, sondern eines, in dem sich beide Versionen eine LSTM-Schicht teilen, ein sogenanntes *siamese LSTM model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           20608       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,673\n",
      "Trainable params: 20,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "lstm_shared = layers.LSTM(32) # gemeinsame Schicht\n",
    "\n",
    "left_input = Input(shape=(None, 128)) # variable length input of size 128\n",
    "left_output = lstm_shared(left_input) # sind outputs, die über lstm_shared entstehen, wenn Input linker Input ist\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm_shared(right_input) \n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis = -1)\n",
    "predictions = layers.Dense(1, activation = 'sigmoid')(merged) \n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
