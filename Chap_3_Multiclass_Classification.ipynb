{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Multiclass Classification</h1><br>\n",
    "Es gibt dabei single-lable multiclass classification, bei der eine Beobachtung nur einer Klasse zugeordnet werden kann. Daraus folgt multi-lable ..., bei der eine Beobachtung zu mehreren Klassen gleichzeitig gehören kann.<br><br>\n",
    "<b>Der Reuters-Datensatz</b><br>\n",
    "Textklassifikation: kurze Nachrichten mit dem dazugehörigen Thema. Es gibt 46 Themen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)\n",
    "# es gilt wieder, dass jede Beobachtung nur aus den 10 000 häufigsten Wörtern besteht\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kann man wie bei der binären Klassifikation Daten in natürliche Sprache zurückumwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531\n",
      "? oper shr 40 cts vs 30 cts oper net 1 364 000 vs 1 025 000 revs 14 7 mln vs 11 0 mln avg shrs 3 372 970 vs 3 425 400 year oper shr 86 cts vs 32 cts oper net 2 925 000 vs 1 109 000 revs 43 0 mln vs 35 7 mln avg shrs 3 383 651 vs 3 418 594 note year ago periods exclude extraordinary gain of 1 1 mln dlrs or 31 cts shr includes gains of 988 000 dlrs vs one mln dlrs in qtr and 2 2 mln dlrs vs 1 1 mln dlrs in year from tax loss carryforwards reuter 3\n"
     ]
    }
   ],
   "source": [
    "index = reuters.get_word_index()\n",
    "print(index['car']) # assziativer Array, Wort -> Zahl 'Dictionary' in Python\n",
    "# index.items() wandelt ein dict in Paare von zugeordneten Werten um\n",
    "# und dict() wandelt Tupel wieder in dicts um\n",
    "index_reversed = dict([(num, word) for (word, num) in index.items()])\n",
    "# hat einen Offset von 3, weil die ersten 3 für \"padding\", \"start\" und \"unknown\" stehen\n",
    "print(' '.join([index_reversed.get(i - 3, '?') for i in train_data[28]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun geht es wieder ans Umwandeln der Daten in One-Hot-Kodierung für das NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12] \n",
      "\n",
      "[0. 1. 1. ... 0. 0. 0.]\n",
      "[list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12])\n",
      " list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12])\n",
      " list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])\n",
      " ...\n",
      " list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12])\n",
      " list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12])\n",
      " list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hottify(newswire, num_classes):\n",
    "    results = np.zeros((1, num_classes)).flatten()    \n",
    "    for num in newswire:\n",
    "        results[num] = 1        \n",
    "    return results\n",
    "\n",
    "news = train_data[0]\n",
    "print(news, '\\n')\n",
    "print(one_hottify(news, 10000))\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2163, 317, 65, 131, 1462, 23, 768, 1225, 2, 7, 316, 5, 10, 3851, 1017, 97, 2201, 267, 2093, 248, 705, 9, 387, 262, 2, 4805, 118, 10, 163, 483, 36, 118, 4, 978, 427, 691, 491, 8140, 303, 522, 144, 34, 10, 2783, 5, 1236, 10, 1026, 24, 41, 8244, 4, 816, 168, 7372, 184, 75, 163, 126, 5, 4, 3579, 2164, 4805, 34, 3051, 6, 10, 1031, 515, 106, 909, 5, 65, 4274, 4805, 8, 144, 62, 7854, 5, 2, 696, 3851, 8034, 6, 65, 182, 4274, 64, 875, 548, 336, 7, 329, 206, 405, 439, 4, 825, 7, 4, 1142, 3813, 317, 6227, 101, 21, 2, 2552, 2988, 65, 1523, 254, 397, 5767, 6, 401, 20, 22, 193, 20, 9, 4, 5414, 5, 6227, 21, 4886, 65, 292, 54, 397, 36, 8, 4, 182, 250, 4, 8140, 40, 85, 2629, 13, 4, 3984, 5, 4169, 4274, 21, 65, 7, 809, 6, 842, 2247, 13, 9370, 112, 10, 7556, 5, 1490, 87, 9, 2163, 1577, 456, 691, 411, 184, 6223, 1381, 6, 1144, 226, 8211, 2, 6, 42, 414, 2828, 4274, 6476, 268, 1648, 8799, 6, 2563, 405, 6771, 5, 2, 8034, 984, 5, 6272, 756, 50, 2069, 106, 995, 389, 717, 9, 91, 325, 2069, 10, 1716, 5, 2512, 43, 6, 432, 2210, 201, 55, 819, 6, 391, 7, 181, 714, 4805, 8, 36, 8, 4, 106, 299, 45, 2466, 6, 455, 25, 3759, 9215, 4274, 2, 998, 189, 254, 1677, 7, 807, 6, 182, 1343, 6, 837, 137, 691, 1741, 7, 10, 630, 654, 6, 30, 2, 43, 384, 257, 2, 23, 10, 131, 5, 279, 20, 923, 6, 2237, 5261, 1304, 714, 267, 21, 454, 92, 10, 608, 101, 5, 810, 40, 85, 1980, 13, 2210, 1640, 8140, 40, 8, 16, 23, 45, 10, 3853, 74, 267, 131, 161, 691, 2, 23, 923, 6, 1633, 1640, 4805, 8, 4, 534, 45, 6, 455, 2, 34, 267, 95, 97, 1866, 21, 4, 816, 3515, 6, 2223, 4, 2, 9, 847, 5, 4, 73, 6476, 787, 24, 181, 1118, 57, 414, 85, 731, 21, 4, 1053, 2982, 1001, 17, 12] \n",
      "\n",
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "one_hot_train_data = [one_hottify(news, 10000) for news in train_data]\n",
    "one_hot_test_data = [one_hottify(news, 10000) for news in test_data]\n",
    "print(train_data[29], '\\n')\n",
    "print(one_hot_train_data[29])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich um ein Multiklassen-Problem handelt, müssen die Labels auch erst in One-Hot umgewandelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 0\n",
      "3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "max_num = max(train_labels)\n",
    "min_num = min(train_labels)\n",
    "print(max_num, min_num) # Es gibt 46 Klassen\n",
    "max_classes = max_num + 1\n",
    "\n",
    "def label_one_hottify(num, max_classes):\n",
    "    # has to deal with single numbers, not arrays\n",
    "    res = np.zeros((1, max_classes)).flatten()\n",
    "    res[num] = 1\n",
    "    return res\n",
    "\n",
    "one_hot_train_labels = [label_one_hottify(label, max_classes) for label in train_labels]\n",
    "one_hot_test_labels = [label_one_hottify(label, max_classes) for label in test_labels]\n",
    "print(train_labels[28], one_hot_train_labels[28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bau des Netzwerks</b><br>\n",
    "Es wichtig zu verstehen, dass jede Schicht ihre Informationen aus der vorangegangenen Schicht bezieht. Verlorengegangene Information ist nicht wiederherstellbar. Diese kann verloren gehen, indem z.B. eine Schicht weniger Knoten hat als die Outputschicht. Das heißt, diese Schicht stellt die Information des Inputs in weniger Knoten dar als die des Outputs und komprimiert Information über das geforderte Maß der letzten Schicht hinaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu', input_shape = (10000, )))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
