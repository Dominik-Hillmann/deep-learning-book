{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing</h1><br><br>\n",
    "Hier ist es das Ziel, die Daten für das NN besser verdaulich zu machen. Einige wichtige Punkte: Alle Inputs müssen float32-Vektoren sein. Egal welche Daten, sie müssen zunächst vektorisiert werden. Beispiel: Text -> Platzierung in Häufigkeit der 10000 -> One-Hot-Vektor mit 10000 Elementen. Oder grayscale-Bilder (Matrix mit 0 - 255 als Werten) -> Vektor -> Werte mit 0-1.<br>\n",
    "Außerdem solltest du dafür Sorge tragen, dass alle Inputwerte im gleichen Bereich liegen und dass diese ungefähr in der Größenordnung -1 bis 1 liegen. Darum wurden die Daten beim Boston-Datensatz auch normalisiert.<br><br>\n",
    "<b>Vermisste Werte</b><br>\n",
    "Es ist ausreichend, vermisste Werte mit 0 zu kodieren, wenn dies keine andere Bedeutung einnimmt. Das NN lernt, die 0 zu interpretieren.<br><br>\n",
    "<b>Feature Engineering</b><br>\n",
    "... ist die Erstellung einer besseren Darstellung eines Features, die hard-coded erstellt werden kann. Der Algorithmus soll die Darstellung besser verstehen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
