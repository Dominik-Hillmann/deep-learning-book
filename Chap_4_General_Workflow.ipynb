{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A General Workflow When Constructing Deep Neural Networks</h1><br><br>\n",
    "Als erstes, was ist das Problem, was ist der Input, was ist der Output? Ist es eine Multiklassenklassifikation, eine binäre Klassifikation, Regression? Wenn du dich entschlossen hast, das Problem mittels ML zu lösen, stellst du zwei Hypothesen über dieses Problem auf. Zum einen sagst du, dass die Inputs Voraussagekraft für die Outputs haben und zum anderen, dass in den gegebenen Daten genug Information enthalten ist, um das Problem auf diese Weise zu lösen.<br><br>\n",
    "<b>Die Erfolgsmetrik</b><br>\n",
    "Woran wird gemessen, dass dein Modell die Werte richtig voraussagt? Dieser Metrik solltest du die Verlustfunktion, also eine Funktion der Differenz der vorausgesagten und echten Werte, angepasst werden. Sie sollte mit den höheren Zielen des Modells zusammenhängen.<br><br>\n",
    "<b>Evaluationsprotokoll</b><br>\n",
    "Wähle aus den vorgestellten Validierungsprotokollen, je weniger, Daten, desto mehr Iterationen, max. p* k.<br><br>\n",
    "<b>Datenvorbereitung</b><br>\n",
    "Wurde bereits beschrieben<br><br>\n",
    "<b>Ein Modell, das Werte besser als die Baseline voraussagt</b><br>\n",
    "Soll heißen, ein Modell, das eine bessere Performance liefert als würde man völlig zufällig wählen. Z.B. bei Klassifikation besser zu sein, als zufällig eine Klasse zu wählen. Oder bei Regressionsproblemen einen kleineren absoluten mittleren Abstand zu haben als würde man immer den Mittelwert nutzen. Funktioniert das, wurde die Hypothese verifiziert, dass die Inputdaten Voraussagekraft für die Outputs haben. Nun müssen <br>\n",
    "- die Aktivierungsfunktion der letzten Schicht,<br>\n",
    "- die Verlustfunktion und<br>\n",
    "- den Optimierer wählen, wobei in den meisten Fällen <code>rmsprop</code> ausreichend ist.<br>\n",
    "Bezüglich typischer Probleme und passender Optimierer, etc., hier eine Liste:<br><br>\n",
    "<table><tr><th><b>Problem</b></th><th><b>Aktivierung letzer Schicht</b></th><th><b>Loss-Funktion</b></th></tr><tr><th>Binäre Klassifikation</th><th>sigmoid</th><th>binary_crossentropy</th></tr><tr><th>Multiclass, single label</th><th>softmax</th><th>categorical_crossentropy</th></tr><tr><th>Multiclass, multi label</th><th>sigmoid</th><th>binary_crossentropy</th></tr><tr><th>Regression auf alle Werte</th><th>nichts</th><th>mse</th></tr><tr><th>Regression auf Werte zwischen 0 und 1</th><th>sigmoid</th><th>mse oder binary_crossentropy</th></tr></table><br>\n",
    "<b>Ein Modell, das Overfittet</b><br>\n",
    "Du hast du nun ein Modell mit Voraussagekraft, ist diese allerdings stark genug? Nun musst du die Grenze zwischen Overfitting und Underfitting gefunden werden. Dazu muss diese übertreten werden. Um das Modell zum Overfitten zu bringen, braucht es mehr Schichte, in diesen mehr Neuronen, und es muss für mehr Epochen traniert werden. Wenn die Performance auf den Validierungsdaten verfällt, hast du dein Ziel erreicht.<br><br>\n",
    "<b>Regularisierung und Tuning der Hyperparameter</b><br>\n",
    "Dieser Schritt braucht am meisten Zeit. Nun wirst du das Modell aufgrund der Performance auf den Validierungsdaten wiederholt verbessern. Allerdings nicht zu oft aufgrund des information leak. Hat dein Modell eine zufriedenstellende Performance, kannst du es auf den Tranings- und Validierungsdaten tranieren und ein letztes Mal auf den Testdaten testen. Sollte die Performance hier viel schlechter sein, war der information leak zu groß. Dann solltest du ein genaueres Validierungsprotokoll nutzeb,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
