{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regressionsprobleme mit Neuronalen Netzen</h1><br>\n",
    "Hier warten nun ganz andere Probleme, z.B. unterschiedliche Skalierung der Inputvariablen.<br><br><b>Der Boston Housing Price-Datensatz</b><br>\n",
    "Dieser ist recht klein, 506 Beobachtungen, wobei jedes Feature eine andere Skalierung hat. Die Ziele sind die die Medianwerte der Häuser in Tsd. Dollar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "[  0.67191   0.        8.14      0.        0.538     5.813    90.3\n",
      "   4.682     4.      307.       21.      376.88     14.81   ] \n",
      " 16.6\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "print(train_data.shape) # 404 Beobachtungen mit 13 Variablen\n",
    "print(train_data[28], '\\n',train_targets[28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten müssen bei unterschiedlicher Skalierung nicht präpariert werden, indem sie One-Hot-kodiert werden. Hier müssen sie normalisiert werden. Wie bei der Hauptkomponentenanalyse. Dafür gibt es in np-Arrays eingebaute Methoden, die mithilfe von axis = 0 die Statistiken für das jeweilige Feature/die jeweilige Variable finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.74511057e+00 1.14801980e+01 1.11044307e+01 6.18811881e-02\n",
      " 5.57355941e-01 6.26708168e+00 6.90106436e+01 3.74027079e+00\n",
      " 9.44059406e+00 4.05898515e+02 1.84759901e+01 3.54783168e+02\n",
      " 1.27408168e+01]\n",
      "[  0.67191   0.        8.14      0.        0.538     5.813    90.3\n",
      "   4.682     4.      307.       21.      376.88     14.81   ]\n",
      "[-0.3329834  -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.64053626\n",
      "  0.76289357  0.4644321  -0.62624905 -0.59517003  1.14850044  0.23508618\n",
      "  0.28557943]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.mean(axis = 0))\n",
    "print(train_data[28])\n",
    "\n",
    "means = train_data.mean(axis = 0)\n",
    "std_deviations = train_data.std(axis = 0)\n",
    "train_data -= means\n",
    "train_data /= std_deviations\n",
    "\n",
    "print(train_data[28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Problem mit kleinen Datensätzen wie diesem hier, dass sie leicht zum Overfitting führen. Um dem etwas entgegenzusetzen, werden relativ kleine Netze verwendet. Das sollte verhindern, dass sich ein zu großes Netz auf die nicht-generalisierbaren Eigenheiten der Trainingsdaten einpendeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # will have multiple instances, that's why we use a function\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(\n",
    "        64, activation = 'relu', \n",
    "        input_shape = (train_data.shape[1], )\n",
    "    ))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = 'rmsprop',\n",
    "        loss = 'mse',\n",
    "        metrics = ['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die letzte Schicht endet mit einem einzelnen Neuron und ohne Aktivierungsfunktion, ist also linear, da uns ja der uneingeschränkte Outputwert, also der vorausgesagte Wert des Hauses, interessiert. Würdest du z.B. die Sigmoid über das letzte Neuron legen, würden die linearen Werten auf [0,1] abgebildet werden. Ist nicht unser Ziel. Die Loss Function ist nun der MSE, Mean Squared Error, die quadrierte Differenz zwischen dem Ziel und dem vorausgesagten Wert. Der beobachtete Kennwert ist MAE, mean absolute error, also der nicht-quadrierte MSE, einfach nur die Abweichung Ziel <=> Voraussage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>K-Fold-Validation</b><br><br>\n",
    "Wenn Datensätze bereits klein sind, kann ein weiteres Aussieben der Validierungsdaten dem Modell nur schaden, weil das Ergebnis sehr davon abhängig ist, welche wenige Datenpunkte noch über sind.<br>\n",
    "Darum wird diese Technik genutzt. Die Daten werden in k Teile partitioniert. Es werden k Modelle trainiert auf k - 1 Teilen, wobei 1 Teil der Validierung dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "Processing fold 1.\n",
      "303 101\n",
      "Processing fold 2.\n",
      "303 101\n",
      "Processing fold 3.\n",
      "303 101\n",
      "Processing fold 4.\n",
      "303 101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "print(int(len(train_data) / k))\n",
    "num_val_samples = int(len(train_data) / k)\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('Processing fold ' + str(i + 1) + '.')\n",
    "    # Daten, von : bis\n",
    "    val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate([\n",
    "        train_data[:i * num_val_samples],      # alles vor Validierungsdaten\n",
    "        train_data[(i + 1) * num_val_samples:] # alles nach Validierungsdaten\n",
    "    ], axis = 0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([\n",
    "        train_targets[:i * num_val_samples],      # alles vor Validierungsdaten\n",
    "        train_targets[(i + 1) * num_val_samples:] # alles nach Validierungsdaten\n",
    "    ], axis = 0)\n",
    "    \n",
    "    print(len(partial_train_data), len(val_data))\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(\n",
    "        np.array(partial_train_data),\n",
    "        np.array(partial_train_targets),\n",
    "        epochs = num_epochs,\n",
    "        batch_size = 1,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    (mse, mae) = model.evaluate(x = val_data, y = val_targets, verbose = 0)\n",
    "    print('MAE:', mae)\n",
    "    all_scores.append(mae)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.063244300313515, 2.2822579416898217, 2.947527550234653, 2.378170597671282] 2.417800097477318\n",
      "$5000 bis $50000\n"
     ]
    }
   ],
   "source": [
    "print(all_scores, np.mean(all_scores))\n",
    "# Ein MAE von 2.42 bedeutet, dass durchschnittlich noch $2400 Fehler existiert,\n",
    "# was viel ist bei Preisen von\n",
    "print(\n",
    "    '$' + str(int(min(train_targets)) * 1000), \n",
    "    'bis',\n",
    "    '$' + str(int(max(train_targets))* 1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun optimieren wir die Schleife ein wenig. Zum einen lassen wir sie nun 500 Epochen laufen, also 500 Durchläufe durch die Trainingsdaten: 500 Mal mit jeder Aufteilung Validierung/Trainigsdaten. Wir wollen uns nun aber anschauen, wann der Fehler für die Validierungsdaten in Abhängigkeit von der aktuellen Epoche minimiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1.\n",
      "303 101\n",
      "Processing fold 2.\n",
      "303 101\n",
      "Processing fold 3.\n",
      "303 101\n",
      "Processing fold 4.\n",
      "303 101\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = int(len(train_data) / k)\n",
    "num_epochs = 1500\n",
    "all_mae_hists = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('Processing fold ' + str(i + 1) + '.')\n",
    "    # Daten, von : bis\n",
    "    val_data = train_data[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate([\n",
    "        train_data[:i * num_val_samples],      # alles vor Validierungsdaten\n",
    "        train_data[(i + 1) * num_val_samples:] # alles nach Validierungsdaten\n",
    "    ], axis = 0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([\n",
    "        train_targets[:i * num_val_samples],      # alles vor Validierungsdaten\n",
    "        train_targets[(i + 1) * num_val_samples:] # alles nach Validierungsdaten\n",
    "    ], axis = 0)\n",
    "    \n",
    "    print(len(partial_train_data), len(val_data))\n",
    "    \n",
    "    model = build_model()\n",
    "    hist = model.fit(\n",
    "        np.array(partial_train_data),\n",
    "        np.array(partial_train_targets),\n",
    "        epochs = num_epochs,\n",
    "        batch_size = 1,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    all_mae_hists.append(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "dict_keys(['loss', 'mean_absolute_error'])\n",
      "4 1500\n"
     ]
    }
   ],
   "source": [
    "print(len(all_mae_hists))\n",
    "print(all_mae_hists[0].keys())\n",
    "mae_means = [all_mae_hists[i]['mean_absolute_error'] for i in range(len(all_mae_hists))]\n",
    "print(len(mae_means), len(mae_means[0]))\n",
    "# also 4 Folds, mit je dem MAE der 300 Epochen\n",
    "# Wir bilden den Durchschnitt der 4 Folds über die 300 Epochen\n",
    "\n",
    "mae_fold_means = [\n",
    "    np.mean([mae[i] for mae in mae_means]) \n",
    "    for i in range(num_epochs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nun machen wir Plots daraus\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.plot(range(1, len(mae_fold_means) + 1), mae_fold_means)\n",
    "plot.xlabel('Epoches')\n",
    "plot.ylabel('Mean MAE over folds')\n",
    "plot.show()\n",
    "\n",
    "# villeicht ist das die MAE für Traniningsdaten?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
