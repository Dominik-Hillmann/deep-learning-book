{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Die Convolution und Pooling Operationen</h1><br>\n",
    "Convolutional Neural Networks dienen der Arbeit mit Bildern. Ihre Genauigkeit übertrifft denen normaler NNs. Das liegt daran, dass bevor die Bilder in dicht vernetzte Schichten (<code>Dense</code>) eingespeist werden, werden sie durch zwei andere Arten von Schichten geschickt.<br><br>\n",
    "<b>Die Convolution-Operation</b><br>\n",
    "Abstrakt gesagt ist der Unteschied zwischen normalen NNs und CNNs, dass CNNs lokale Muster lernen, während NNs sich auf gloable Muster beschränken müssen. Dabei lernen die Convolutional Schichten die lokalen Muster. Ist eine Muster an einer Stelle im Bild gelernt, kann es überall wiedererkannt werden. Mehrere Convolutional Schichten hintereinander können komplexere Muster im Bild erkennen und somit etwas anhand komplexer Konzepte im Bild erkennen. Das passiert, indem die einfachen Muster der ersten Convolution-Schicht, wie \"vertikaler Strich\" oder \"Strich von oben links nach unten rechts\", sich in darauffolgenden Schichten zu komplexeren Mustern zusammensetzen, wie \"Ohr\" oder \"Auge\" beim Erkennen menschlicher Gesichter.<br><br><img src=\"./imgs/cnn_cat.png\"><br><br>\n",
    "Der Input in ein CNN sind Bilder mit den Dimensionen <code>(height, width, channels)</code>. Die Channels beschreiben z.B. Farbanteile wie rot, grün, blau (RGB). Im Falle von RGB wären es also drei Channel. Im Falle eines schwarz-weißen Bildes wäre es 1, die Graustufen. Die Convolution extrahiert darauf kleinere Teile des Bildes, meist der Größe (3, 3) oder (5, 5). Über diese wird Pixel für Pixel ein Filter geschoben, der kleine Muster, wie z.B. \"querer Strich\" kodiert. Der Rückgabewert der Schicht ist dann ein Tensor der Dimension <code>(height - k, width - k, Anzahl Filter)</code>. k sind ein oder zwei Pixel am Rand, die nicht mit einbezogen werden können, weil die Filter sonst teilweise nicht im Bild liegen würden. Jeder Filter gibt eine sogenannte Response Map (<code>(height - k, width - k, 1)</code>) zurück, die zeigt, welche Teile des Bilder am ehesten dem Filter entsprechen.<br><br><img src=\"./imgs/cnn_filter.png\"><br><br>\n",
    "Dabei wird zuerst der kleine Teil extrahiert. Das \"filtern\" erfolgt über Matrixoperation mit einem Kernel. Der Kernel kodiert das Konzept, indem er die Bedeutung der Pixel um den Mittelpixel gewichtet. Die Berechnung erfolgt dann mittels der Matrixmultiplikation zwischen Ausschnitt und Kernel/Filter für jeden Kernel (Anzahl Kernel -> Output Depth), Dimension <code>(1, 1, Anzahl Filter)</code>. Dann wird der Ausschnitt untersucht, der sich einen Pixel weiter befindet, wiederholt, usw. Die 1 * 1 Ausschnitte werden dann woeder zur Feature Map zusammengesetzt für jeden der Kernel.<br><br><img src=\"./imgs/cnn_feature_maps.png\"><br><br>\n",
    "Will man eine Feature Map als Output, die die gleichen Dimensionen hat wie die des Inputs, kann man dies über das Padding steuern. Padding fügt dem Bild am Rand genügend Pixel hinzu, sodass der Ausschnitt niemals außerhalb des Bildes liegen kann. Außerdem beeinflusst das Striding die Größe des Outputs. Striding beschreibt, um wie viele Pixel der Ausschnitt springt. Allerdings wird selten ein Striding != 1 genutzt.<br><br>\n",
    "<b>Die Max-Pooling-Operation</b><br><br>\n",
    "Diese Schichten werden genutzt, um ein Bild aggressiv zu verkleinern. Ähnlich den Convolution-Schichten entziehen sie dem Bild kleinere Bilder. Meistens bestehen diese kleineren Bilder aus 2 * 2-Ausschnitten mit einem Stride von 2, also existiert keine Überlappung. Aus diesen Ausschnitten wird eine der Maximalwert entnommen und in die nächste Schicht eingespeist. Aber warum sollte das getan werden? Zum einen werden dadurch die Muster \"gepresst\", sodass Muster auf einem höheren Level gelernt werden können und zum anderen bedürften das Modell sonst zu viele Parameter, was zu Overfitting führt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small noch nicht vorhanden.\n",
      "Sets noch nicht vorhanden.\n",
      "Unterteilungen noch nicht vorhanden.\n",
      "\n",
      "\n",
      "dog.28.jpg\n",
      "dog.1028.jpg\n",
      "dog.1528.jpg\n",
      "cat.28.jpg\n",
      "cat.1028.jpg\n",
      "cat.1528.jpg\n"
     ]
    }
   ],
   "source": [
    "# Aus Datensatz einen kleineren zum üben erstellen\n",
    "import os, shutil\n",
    "\n",
    "# create new directory for downsized dataset\n",
    "org_data_dir = '/home/dominik/Documents/Datasets/cats_and_doggos/train'\n",
    "small_data_dir = '/home/dominik/Documents/Datasets/cats_and_doggos/small'\n",
    "if not os.path.isdir(small_data_dir):\n",
    "    os.mkdir(small_data_dir)\n",
    "    print('Small noch nicht vorhanden.')\n",
    "else:\n",
    "    print('Small vorhanden.')\n",
    "\n",
    "# directories train, validation and test\n",
    "train_dir = os.path.join(small_data_dir, 'train')\n",
    "val_dir = os.path.join(small_data_dir, 'val')\n",
    "test_dir = os.path.join(small_data_dir, 'test')\n",
    "\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(val_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    print('Sets noch nicht vorhanden.')\n",
    "else:\n",
    "    print('Sets vorhanden.')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cat')\n",
    "val_cats_dir = os.path.join(val_dir, 'cat')\n",
    "test_cats_dir = os.path.join(test_dir, 'cat')\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dog')\n",
    "val_dogs_dir = os.path.join(val_dir, 'dog')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dog')\n",
    "\n",
    "if not os.path.isdir(train_cats_dir):\n",
    "    print('Unterteilungen noch nicht vorhanden.')\n",
    "    os.mkdir(train_cats_dir)\n",
    "    os.mkdir(val_cats_dir)\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "    os.mkdir(train_dogs_dir)\n",
    "    os.mkdir(val_dogs_dir)\n",
    "    os.mkdir(test_dogs_dir)\n",
    "else:\n",
    "    print('Unterteilungen bereits vorhanden.')\n",
    "\n",
    "print('\\n')\n",
    "if not os.path.exists(os.path.join(train_cats_dir, 'cat.28.jpg')):\n",
    "    set_ranges = {\n",
    "        'train': range(1000),\n",
    "        'val': range(1000, 1500),\n",
    "        'test': range(1500, 2000)\n",
    "    }\n",
    "    \n",
    "    for animal in ['dog', 'cat']:\n",
    "        for set in ['train', 'val', 'test']:\n",
    "            \n",
    "            file_names = ['{0}.{1}.jpg'.format(animal, i) for i in set_ranges[set]]\n",
    "            print(file_names[28])\n",
    "            \n",
    "            for file_name in file_names:\n",
    "                src = os.path.join(org_data_dir, file_name)\n",
    "                dst = os.path.join(small_data_dir, set, animal, file_name)\n",
    "                shutil.copyfile(src, dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
