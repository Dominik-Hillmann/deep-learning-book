{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fine-Tuning</h1><br><br>\n",
    "Ist eine Technik, die neben der Feature-Extraction existiert bereits trainierte Convolution-Schichten anderer Modelle nutzt. Dabei werden die obersten Convolution-Schichten wieder aufgetaut und während des Tranings mit angepasst. Auf diese Weise werden die abstraktesten dargestellten Konzepte dieser Schichten so verändert, dass sie eher Konzepte des aktuellen Problems verkörpern. Hier besteht wieder das Problem, dass die Updates zu groß wären, wenn die Gewichte der <code>Dense</code>-Schichten zufällig initialisiert sind. Deswegen wird folgendermaßen vorgegangen:\n",
    "\n",
    "1. Füge deine eigenes Netzwerk den trainierten Convolution-Schichten hinzu\n",
    "2. Friere <b>alle</b> Convolution-Schichten ein\n",
    "3. Trainiere den Teil, den du hinzugefügt hast\n",
    "4. Taue die gewünschten Convoltion-Schichten wieder auf\n",
    "5. Trainiere nun deine Schichten und die aufgetauten Schichten zusammen<br>\n",
    "\n",
    "Warum nicht mehr Schichten trainieren als nur die obersten? Weil die obersten schichten sehr spezielle, auf das vorige Problem angepasste Muster speicherten. Die unteren Schichten kodieren sehr viel generischere Muster und sind so auf mehr Problem anwendbar. Außerdem, je mehr Parameter trainiert werden, desto größer ist die Gefahr des Overfitting, was bei kleinen Datensätzen riskant ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False, # soll der Klassifizierer mit einbezogen werden?\n",
    "    input_shape = (150, 150, 3) # Wie große sind die Bilder? (height, width, channels (rgb))\n",
    ")\n",
    "conv_base.summary()\n",
    "\n",
    "# Wir wollen nur Block 5 trainieren:\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainabe = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = True\n",
    "        \n",
    "# Modell kompilieren und fitten, S. 29\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
