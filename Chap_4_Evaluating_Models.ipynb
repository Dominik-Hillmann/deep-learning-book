{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluating Your Model</h1><br><br>\n",
    "Das Ziel des maschinellen Lernen ist es, Modelle zu bauen, die sich möglichst gut auf nicht gesehene Daten übertragen lassen. Wie in den Beispielen zuvor gesehen, setzt nach einigen Epochen das Overfitting ein. Das bedeutet, dass das Modell beginnt, Muster des Traninigdatensatzes zu lernen, die sich nicht auf die Validierungsdaten übertragen lassen. Das Modell ist an die Trainingsdaten überangepasst - overfittet - und kann nicht auf neue Daten übertragen.<br><br>\n",
    "<b>Training, Validierung und Test</b><br>\n",
    "Warum existiert diese Unterteilung? Warum reichen nicht nur Trainings- und Testdaten? Während du dein Modell verbesserst, wirst du Hyperparameter ändern, also die Zahl und Größe der Schichten, Epochenzahl, Batchzahl, etc. Diese änderst du hinsichtlich der Performance auf den Validierungsdaten. Das impliziert auch ein Lernen <k>du</k> änderst die Hyperparamter so, dass sie eine bessere Performance aufweisen. Dadurch entsteht ein 'Information Leak'. Informationen über die Validierungsdaten leaken in das Modell durch deine Verbesserung. Overfitting des Modells auf den Validierungsdatensatz. Dein Modell performt künstlich gut auf deinem Validierungsdatensatz. Du musst die Performance anhand eines noch nie gesehenen Datensatzes, dem Testdatensatz, testen. Das bedeutet aber auch im Umkehrschluss,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
