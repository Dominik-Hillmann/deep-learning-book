{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Das Beispiel-Netzwerk</h1><br>\n",
    "Das zu lösende Probleme soll die Einordnung von 28px mal 28px großen Bildern von Zahlen in Schreibschrift in die Kategorien 0 bis 9 sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "print(train_labels[0])\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Nun wird ein Netzwerk gebaut, dem die Bilder train_images und die Zuordnung train_labels. Daraus entwickelt das Netzwerk Zuordnungen, die anhand des Vergleichs des errechneten Outputs von test_images[i] mit test_labels[i] verglichen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28, )))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Wir bauen ein Netzwerk, das in der ersten Schicht 512 Einheiten besitzt und Daten der Größe <code>(28 * 28, )</code> erwartet. <code>Dense</code> heißt, dass jede Einheit dieser Schicht mit allen Einheiten der vorhergehenden Schicht verbunden ist. Die letzte Schicht besitzt eine <code>softmax</code> Aktivierungsfunktion, was bedeutet, dass sie 10 Wahrscheinlichkeiten für die 10 Kategorien zurückgeben wird.<br>\n",
    "Nun müssen noch drei Dinge definiert werden, bevor das Netzwerk die Arbeite aufnehmen kann:\n",
    "1. Die Loss-Function: wie das Netzwerk Erfolg beim Vergleich mit den Testdaten misst\n",
    "2. Der Optimierer, also wie sich das Netzwerk optimiert, basierend auf der Loss-Function und den Daten\n",
    "3. Die zu beobachtenden Metriken während des Trainings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "network.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bevor das Netzwerk trainiert werden kann, müssen die Daten in Vektoren aus Nullen und Einsen umgewandelt werden. Unsere Trainingsbilder haben die Form <code>(60000, 28, 28)</code>, also 60000 Bilder mit 28 mal 28 Pixeln, wobei jeder Pixel durch eine Zahl zwischen 0 und 255 dargestellt wird, also wie schwarz/weiß dieser ist. Diese werden nun in <code>float32</code>-Werte <i>zwischen</i> 0 und 1 umgewandelt in der Form <code>(60000, 28 * 28)</code> (60000 Beobachtungen mit einem 1D-Array aus Werten zwischen 0 und 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.2562 - acc: 0.9254\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1042 - acc: 0.9688\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0694 - acc: 0.9794\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0499 - acc: 0.9852\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0373 - acc: 0.9887\n",
      "10000/10000 [==============================] - 1s 57us/step\n",
      "Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28)) # neue Form mit flachen Arrays\n",
    "train_images = train_images.astype('float32') / 255 # float32 auf 0...1 normiert\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# labels umwandeln\n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# alles ist getan, das Netzwerk kann traniert werden\n",
    "network.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs = 5,\n",
    "    batch_size = 128\n",
    ")\n",
    "\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Datenrepräsentationen</h1><br>\n",
    "Tensoren sind die generelle Bezeichnung für Vektoren, Matrizen, Skalare, etc. Sie sind die in NN Netzwerk am meisten genutzte Datenrepräsentation.<br><br>\n",
    "<b>Skalare - 0D</b><br>\n",
    "Das sind Tensoren mit nur einer Zahl. In Numpy können float32 oder float64-Zahlen Skalare sein.<br><br>\n",
    "<b>Vektoren - 1D</b><br>\n",
    "Vektoren haben exakt eine Dimension, entlang der Zahlen angeordnet sind.<br><br>\n",
    "<b>Matrizen - 2D</b><br>\n",
    "Haben zwei Dimensionen, genannt Zeilen und Spalten. Beispiele für Daten aus der realen Welt, die als Matrix angeordnet sind, sind Daten, bei den für n Beobachtungen p Variablen augezeichnet worden sind: <code>(Beobachtungen, Variablen)</code>.<br><br>\n",
    "<b>3+D</b><br>\n",
    "3D-Tensoren kann man z.B. als Anordnung in einem Würfel interpretieren. Ein Beispiel für 3D-Daten sind Zeitreihendaten, wo wieder für n Beobachtungen p Variablen aufgezeichnet worden sind, dies aber zu T Zeitpunkten wiederholt wurde: <code>(Beobachtungen, Variablen, Zeitpunkte)</code>.<br>\n",
    "4D - Bilder: <code>(Beobachtungen, Px in x-Dimension, Px in y-Dimension, Kanäle (Farben))</code>.<br>\n",
    "5D - Videos: <code>Beobachtungen, Frame, Px in x-Dimension, Px in y-Dimension, Kanäle (Farben))</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n",
      "[12  5  2]\n",
      "[[1. 2. 4.]\n",
      " [5. 2. 5.]\n",
      " [6. 9. 2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print(x) # Skalar\n",
    "print(x.ndim) # so kann man sich zeigen lassen, wie viele Dimensionen Tensor hat\n",
    "\n",
    "print(np.array([12, 5, 2])) # Vektor\n",
    "x = np.array([\n",
    "    [1, 2, 4],\n",
    "    [5, 2, 5],\n",
    "    [6, 9, 2]\n",
    "]).astype('float32')\n",
    "print(x) # Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Manipulation von NumPy-Datentypen</h1><br>\n",
    "Tensoren haben folgende wichtige Eigenschaften:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3, 3)\n",
      "float32\n",
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(x.ndim) # Zahl der Achsen\n",
    "print(x.shape) # wie viele Einheiten entlang jeder Achse: hier 3 Zeilen, 3 Spalten\n",
    "print(x.dtype) # der NumPy-Datentyp\n",
    "\n",
    "print(train_images.ndim)\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Auswählen von Daten aus einem Tensor</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mySlice = train_images[10:100] # Auswahl Beobachtungen 1 bis 99\n",
    "print(mySlice.shape)\n",
    "# ist das gleiche wie\n",
    "mySlice = train_images[10:100, 0:28, 0:28]\n",
    "print(mySlice.shape)\n",
    "\n",
    "# Auswahl der unteren rechten Ecke ALLER Bilder:\n",
    "mySlice = train_images[:, 14:, 14:] # alle Bilder, Px 14 und darüber, px 14 und darüber\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Batches von Daten</b><br>\n",
    "In allen Datensätzen ist der nullte Dimension normalerweise die Dimension der jeweiligen Beobachtung. Diese wird beim Tranining des Modells in Batches aufgeteilt, hier in Batches von 128 Beobachtungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128] # erster Batch Groesse 128 von 0 bis 127\n",
    "batch = train_images[128:256] # zweiter 128 ... 255\n",
    "# batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Tensoroperationen</b><br>\n",
    "Neuronale Netzwerke können auf eine Reihe von Tensoroperationen (bspw. Matrixmultiplikation) reduziert werden, die folgend erklärt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "exampleLayer= layers.Dense(512, activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Diese Schicht kann als eine Funktion interpretiert werden, die einen 2D-Tensor als Input nimmt und ebenso einen 2D-Tensor wieder ausgibt. \n",
    "$$output = relu(dot(W, input) + bias)$$ mit $$relu(x) = max \\{x, 0\\}$$\n",
    "All die Operationen sind Operationen, die auf allen Elementen eines Tensors ausgeführt wird: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  5. -1.]\n",
      "[0. 5. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3]).astype('float32')\n",
    "y = np.array([-2, 3, -4]).astype('float32')\n",
    "z = x + y # elementweise Addition\n",
    "print(z)\n",
    "print(np.maximum(z, 0.)) # elementweise relu-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All diese Operationen auf einzelnen Elementen sind durch Basic Linear Algebra Subprograms (BLAS) unglaublich schnell. Das sind Subroutinen, geschrieben in Fortran oder C, die installiert werden sollten, um all diese Opeartionen schneller zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Broadcasting</b><br>\n",
    "Es sollte für NumPy noch das Prinzip des Broadcasting erwähnt werden, bei dem Tensoren erweitert werden, sodass Operationen mit anderen Tensoren möglich sind, die ohne Erweiterung mathematisch nicht möglich wären. Man kann sich die Implementierung so vorstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2 # x ist eine Matrix, assert heisst: wenn nicht wahr, schmeisse Error\n",
    "    assert len(y.shape) == 1 # y ist ein Vektor\n",
    "    assert x.shape[1] == y.shape[0] # eine Spalte in x ist so lang wie der y-Vektor\n",
    "    x = x.copy() # überschreibe nicht die originale Variable\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j] # also zu jeder Spalte von x wird y addiert\n",
    "            # man kann sagen, y wird solange neben sich selbst gelegt, bis es so gross wie x ist und dann koennen sie addiert werden\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Das Matrix-Produkt kann folgendermaßen ausgedrückt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 2)\n",
      "[[14. 14.]\n",
      " [11. 15.]\n",
      " [10. 14.]]\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 1],\n",
    "    [3, 2, 1]\n",
    "]).astype('float32')\n",
    "\n",
    "y = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 2]\n",
    "]).astype('float32')\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "z = np.dot(x, y)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Umformung von Tensoren</b><br>\n",
    "Das beudeutet, die Spalten und Zeilen eines Tensors so umzuformen, dass sie eine bestimmte Zielform erreichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(6, 1)\n",
      "[[1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]]\n",
      "[[1. 2. 2.]\n",
      " [3. 3. 2.]]\n",
      "[[1. 3.]\n",
      " [2. 3.]\n",
      " [2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 2]\n",
    "]).astype('float32')\n",
    "print(x.shape)\n",
    "\n",
    "x = x.reshape((6, 1))\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "x = x.reshape((2, 3))\n",
    "print(x)\n",
    "\n",
    "# besondere Form: transponieren\n",
    "print(np.transpose(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Optimierung und Gradienten</h1><br>\n",
    "Für bereits erwähnt, kann jede Schicht eines NN ausgedrückt werden als <code>output = relu(dot(W, input) + bias)</code>. Dabei sind W und bias sogenannte trainierbare Parameter, sie repräsentieren das Wissen des NN und werden in einem Schritt genannt <i>zufällige Initialisierung</i> mit Werten belegt, die den Startpunkt für die Optimierung bieten. Nun werden diese Parameter langsam angepasst, abhängig von einem Feedback-Signal. Diese Phase wird das Training des NN genannt. Das passiert in der Training-Loop:\n",
    "1. Hole dir ein Batch von Input samples X und den dazugehörigen Labels y\n",
    "2. Gib X in das NN und erhalte die vorhergesagten Werte y_pred\n",
    "3. Errechne den Verlust, also den Unterschied von y_pred und y\n",
    "4. Aktualisiere die Parameter, sodass der Verlust ein wenig gemindert wird<br>\n",
    "\n",
    "Der schwierige Teil ist Teil 4: wie genau sollen die Gewichte angepasst werden? Alle Funktionen, die im NN genutzt werden sind differenzierbar.<br>\n",
    "Stell dir einen Input-Vektor <code>x</code>, eine Matrix <code>W</code>, Labels <code>y</code> und eine Loss-Funktion <code>loss</code> vor. Wir nutzen <code>W</code> und <code>x</code>, um <code>y_pred</code> zu errechnen: <code>y_pred = dot(W, x)</code>. Dann folgt der Vergleich mit den Labels: <code>loss_value = loss(y_pred, y)</code>.<br>\n",
    "Werden <code>x</code> und <code>y</code> nun eingefroren, kann das System als eine Funktion interpretiert, die die Gewichte auf den Verlust mappt: <code>loss_value = f(W)</code>. Nun wird der Gradient <code>gradient(f)(W)</code> in <code>W = W0</code> ermittelt. Sie stellt die Steigung der Loss-Function dar. Nun muss W mit einem kleinem inkrementellen Schritt <code>step</code> modifiziert werden (<code>W1 = W0 - step * gradient(f)(W0)</code>). Das heißt der Gradient in W0 wird mit dem negativen step multipliziert und dann von W0 abgezogen: <b>jedes Element in W wird ein wenig in die Richtung verändert, die den Loss fallen lässt</b>.\n",
    "<img src=\"./imgs/Loss.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
